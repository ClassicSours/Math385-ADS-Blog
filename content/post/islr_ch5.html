---
title: ISLR Chapter 5
author: Aaron Shaffer
date: '2018-03-30'
slug: islr_ch5
categories:
  - ISLR
  - R
tags:
  - homework
summary: "ISLR Ch5, Exercises #3, #5"
---



<p>ISLR Ch 5: #3, #5</p>
<div id="we-now-review-k-fold-cross-validation." class="section level2">
<h2>3 We now review k-fold cross-validation.</h2>
<p><span class="math inline">\((a)\)</span> Explain how k-fold cross-validation is implemented.</p>
<p>k-fold cross-validation is implemented by chosing a number of folds and then splitting the data into k nearly evenly partitioned</p>
<p><span class="math inline">\((b)\)</span> What are the advantages and disadvantages of k-fold cross-validation relative to:</p>
<blockquote>
<ol style="list-style-type: lower-roman">
<li>The validation set approach?</li>
</ol>
</blockquote>
<blockquote>
<p>Having more than one set of training data allows for a better model. If there is a low amount of a certain population represented in a dataset than a single validation set might not do a good job representing how that low variable represented by the low population predicts the outcomes. The trade for this is time complexity. Since the validation set approach only uses one validation set it is much faster than k-fold cross-validation.</p>
</blockquote>
<blockquote>
<ol start="2" style="list-style-type: lower-roman">
<li>LOOCV?</li>
</ol>
</blockquote>
<blockquote>
<p>Time complexity, k-fold is much faster than LOOCV and its accurate enough. Disadvantage is that it might be less accurate than LOOCV.</p>
</blockquote>
</div>
<div id="in-chapter-4-we-used-logistic-regression-to-predict-the-probability-of-default-using-income-and-balance-on-the-default-data-set.-we-will-now-estimate-the-test-error-of-this-logistic-regression-model-using-the-validation-set-approach.-do-not-forget-to-set-a-random-seed-before-beginning-your-analysis." class="section level2">
<h2>5. In Chapter 4, we used logistic regression to predict the probability of <code>default</code> using <code>income</code> and <code>balance</code> on the <code>Default</code> data set. We will now estimate the test error of this logistic regression model using the validation set approach. Do not forget to set a random seed before beginning your analysis.</h2>
<p><span class="math inline">\((a)\)</span> Fit a logistic regression model that uses income and balance to predict default.</p>
<pre class="r"><code>library(ISLR)
set.seed(1)
summary(glm(default ~ income + balance, data = Default, family = &quot;binomial&quot;))$coefficient %&gt;% pander</code></pre>
<table style="width:90%;">
<colgroup>
<col width="25%" />
<col width="16%" />
<col width="18%" />
<col width="13%" />
<col width="16%" />
</colgroup>
<thead>
<tr class="header">
<th align="center"> </th>
<th align="center">Estimate</th>
<th align="center">Std. Error</th>
<th align="center">z value</th>
<th align="center">Pr(&gt;|z|)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><strong>(Intercept)</strong></td>
<td align="center">-11.54</td>
<td align="center">0.4348</td>
<td align="center">-26.54</td>
<td align="center">2.958e-155</td>
</tr>
<tr class="even">
<td align="center"><strong>income</strong></td>
<td align="center">2.081e-05</td>
<td align="center">4.985e-06</td>
<td align="center">4.174</td>
<td align="center">2.991e-05</td>
</tr>
<tr class="odd">
<td align="center"><strong>balance</strong></td>
<td align="center">0.005647</td>
<td align="center">0.0002274</td>
<td align="center">24.84</td>
<td align="center">3.638e-136</td>
</tr>
</tbody>
</table>
<p><span class="math inline">\((b)\)</span> Using the validation set approach, estimate the test error of this model. In order to do this, you must perform the following steps:</p>
<blockquote>
<ol style="list-style-type: lower-roman">
<li>Split the sample set into a training set and a validation set.</li>
</ol>
</blockquote>
<pre class="r"><code>N &lt;- nrow(Default)
train &lt;- base::sample(N, N / 2)</code></pre>
<blockquote>
<ol start="2" style="list-style-type: lower-roman">
<li>Fit a multiple logistic regression model using only the training observations.</li>
</ol>
</blockquote>
<pre class="r"><code>train.model &lt;- glm(default ~ income + balance, data = Default, family = &quot;binomial&quot;, subset = train)
summary(train.model) %&gt;% pander</code></pre>
<table style="width:89%;">
<colgroup>
<col width="25%" />
<col width="16%" />
<col width="18%" />
<col width="13%" />
<col width="15%" />
</colgroup>
<thead>
<tr class="header">
<th align="center"> </th>
<th align="center">Estimate</th>
<th align="center">Std. Error</th>
<th align="center">z value</th>
<th align="center">Pr(&gt;|z|)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><strong>(Intercept)</strong></td>
<td align="center">-12.08</td>
<td align="center">0.6658</td>
<td align="center">-18.15</td>
<td align="center">1.334e-73</td>
</tr>
<tr class="even">
<td align="center"><strong>income</strong></td>
<td align="center">1.858e-05</td>
<td align="center">7.573e-06</td>
<td align="center">2.454</td>
<td align="center">0.01414</td>
</tr>
<tr class="odd">
<td align="center"><strong>balance</strong></td>
<td align="center">0.006053</td>
<td align="center">0.0003467</td>
<td align="center">17.46</td>
<td align="center">3.047e-68</td>
</tr>
</tbody>
</table>
<p>(Dispersion parameter for binomial family taken to be 1 )</p>
<table style="width:69%;">
<colgroup>
<col width="29%" />
<col width="40%" />
</colgroup>
<tbody>
<tr class="odd">
<td align="center">Null deviance:</td>
<td align="center">1457.0 on 4999 degrees of freedom</td>
</tr>
<tr class="even">
<td align="center">Residual deviance:</td>
<td align="center">734.4 on 4997 degrees of freedom</td>
</tr>
</tbody>
</table>
<blockquote>
<ol start="3" style="list-style-type: lower-roman">
<li>Obtain a prediction of default status for each individual in the validation set by computing the posterior probability of default for that individual, and classifying the individual to the default category if the posterior probability is greater than 0.5.</li>
</ol>
</blockquote>
<pre class="r"><code>preds &lt;- ifelse(predict(train.model, newdata = Default[-train,], type = &quot;response&quot;) &gt; .5, &quot;Yes&quot;, &quot;No&quot;)</code></pre>
<blockquote>
<ol start="4" style="list-style-type: lower-roman">
<li>Compute the validation set error, which is the fraction of the observations in the validation set that are misclassified.</li>
</ol>
</blockquote>
<pre class="r"><code>mean(preds != Default$default)</code></pre>
<pre><code>## [1] 0.0477</code></pre>
<blockquote>
<p>The validation set error for this data is 4.77%</p>
</blockquote>
<p><span class="math inline">\((c)\)</span> Repeat the process in <span class="math inline">\((b)\)</span> three times, using three different splits of the observations into a training set and a validation set. Comment on the results obtained.</p>
<pre class="r"><code>for(i in c(1:3)) {
  train &lt;- base::sample(N, N / 2)
  train.model &lt;- glm(default ~ income + balance, data = Default, 
                     family = &quot;binomial&quot;, subset = train)
  preds &lt;- ifelse(predict(train.model, newdata = Default[-train,], 
                          type = &quot;response&quot;) &gt; .5, &quot;Yes&quot;, &quot;No&quot;)
  cat(summary(train.model) %&gt;% pander)
  cat(sprintf(&quot;&gt; The validation set error of split:%d of this dataset is %.2f%%\n\n&quot;,i,mean(preds != Default$default) * 100))
}</code></pre>
<table style="width:89%;">
<colgroup>
<col width="25%" />
<col width="16%" />
<col width="18%" />
<col width="13%" />
<col width="15%" />
</colgroup>
<thead>
<tr class="header">
<th align="center"> </th>
<th align="center">Estimate</th>
<th align="center">Std. Error</th>
<th align="center">z value</th>
<th align="center">Pr(&gt;|z|)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><strong>(Intercept)</strong></td>
<td align="center">-11.36</td>
<td align="center">0.5982</td>
<td align="center">-18.99</td>
<td align="center">2.177e-80</td>
</tr>
<tr class="even">
<td align="center"><strong>income</strong></td>
<td align="center">2.264e-05</td>
<td align="center">6.947e-06</td>
<td align="center">3.259</td>
<td align="center">0.001116</td>
</tr>
<tr class="odd">
<td align="center"><strong>balance</strong></td>
<td align="center">0.00553</td>
<td align="center">0.0003142</td>
<td align="center">17.6</td>
<td align="center">2.476e-69</td>
</tr>
</tbody>
</table>
<p>(Dispersion parameter for binomial family taken to be 1 )</p>
<table style="width:69%;">
<colgroup>
<col width="29%" />
<col width="40%" />
</colgroup>
<tbody>
<tr class="odd">
<td align="center">Null deviance:</td>
<td align="center">1483.8 on 4999 degrees of freedom</td>
</tr>
<tr class="even">
<td align="center">Residual deviance:</td>
<td align="center">829.1 on 4997 degrees of freedom</td>
</tr>
</tbody>
</table>
<blockquote>
<p>The validation set error of split:1 of this dataset is 4.85%</p>
</blockquote>
<table style="width:89%;">
<colgroup>
<col width="25%" />
<col width="16%" />
<col width="18%" />
<col width="13%" />
<col width="15%" />
</colgroup>
<thead>
<tr class="header">
<th align="center"> </th>
<th align="center">Estimate</th>
<th align="center">Std. Error</th>
<th align="center">z value</th>
<th align="center">Pr(&gt;|z|)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><strong>(Intercept)</strong></td>
<td align="center">-12.37</td>
<td align="center">0.6649</td>
<td align="center">-18.61</td>
<td align="center">2.918e-77</td>
</tr>
<tr class="even">
<td align="center"><strong>income</strong></td>
<td align="center">2.566e-05</td>
<td align="center">7.175e-06</td>
<td align="center">3.577</td>
<td align="center">0.0003479</td>
</tr>
<tr class="odd">
<td align="center"><strong>balance</strong></td>
<td align="center">0.006042</td>
<td align="center">0.0003452</td>
<td align="center">17.5</td>
<td align="center">1.375e-68</td>
</tr>
</tbody>
</table>
<p>(Dispersion parameter for binomial family taken to be 1 )</p>
<table style="width:69%;">
<colgroup>
<col width="29%" />
<col width="40%" />
</colgroup>
<tbody>
<tr class="odd">
<td align="center">Null deviance:</td>
<td align="center">1463.7 on 4999 degrees of freedom</td>
</tr>
<tr class="even">
<td align="center">Residual deviance:</td>
<td align="center">739.5 on 4997 degrees of freedom</td>
</tr>
</tbody>
</table>
<blockquote>
<p>The validation set error of split:2 of this dataset is 4.77%</p>
</blockquote>
<table style="width:89%;">
<colgroup>
<col width="25%" />
<col width="16%" />
<col width="18%" />
<col width="13%" />
<col width="15%" />
</colgroup>
<thead>
<tr class="header">
<th align="center"> </th>
<th align="center">Estimate</th>
<th align="center">Std. Error</th>
<th align="center">z value</th>
<th align="center">Pr(&gt;|z|)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><strong>(Intercept)</strong></td>
<td align="center">-11.42</td>
<td align="center">0.6128</td>
<td align="center">-18.63</td>
<td align="center">1.896e-77</td>
</tr>
<tr class="even">
<td align="center"><strong>income</strong></td>
<td align="center">2.383e-05</td>
<td align="center">7.184e-06</td>
<td align="center">3.317</td>
<td align="center">0.0009084</td>
</tr>
<tr class="odd">
<td align="center"><strong>balance</strong></td>
<td align="center">0.005471</td>
<td align="center">0.0003123</td>
<td align="center">17.52</td>
<td align="center">1.029e-68</td>
</tr>
</tbody>
</table>
<p>(Dispersion parameter for binomial family taken to be 1 )</p>
<table style="width:69%;">
<colgroup>
<col width="29%" />
<col width="40%" />
</colgroup>
<tbody>
<tr class="odd">
<td align="center">Null deviance:</td>
<td align="center">1436.7 on 4999 degrees of freedom</td>
</tr>
<tr class="even">
<td align="center">Residual deviance:</td>
<td align="center">780.8 on 4997 degrees of freedom</td>
</tr>
</tbody>
</table>
<blockquote>
<p>The validation set error of split:3 of this dataset is 4.39%</p>
</blockquote>
<blockquote>
<p>All three new splits of the data had an error in the ~4.5% region the estimates and all of other values from the linear models are also all very close to eachother. This shows that splitting the data in half produces variable results all very close to eachother.</p>
</blockquote>
<p><span class="math inline">\((d)\)</span> Now consider a logistic regression model that predicts the probability of default using income , balance , and a dummy variable for student . Estimate the test error for this model using the validation set approach. Comment on whether or not including a dummy variable for student leads to a reduction in the test error rate.</p>
<pre class="r"><code>train &lt;- base::sample(N, N / 2)
train.model &lt;- glm(default ~ income + balance + student, data = Default, family = &quot;binomial&quot;, subset = train)
preds &lt;- ifelse(predict(train.model, newdata = Default[-train,], type = &quot;response&quot;) &gt; .5, &quot;Yes&quot;, &quot;No&quot;)
summary(train.model) %&gt;% pander</code></pre>
<table style="width:89%;">
<colgroup>
<col width="25%" />
<col width="18%" />
<col width="18%" />
<col width="13%" />
<col width="13%" />
</colgroup>
<thead>
<tr class="header">
<th align="center"> </th>
<th align="center">Estimate</th>
<th align="center">Std. Error</th>
<th align="center">z value</th>
<th align="center">Pr(&gt;|z|)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><strong>(Intercept)</strong></td>
<td align="center">-10.3</td>
<td align="center">0.6694</td>
<td align="center">-15.38</td>
<td align="center">2.24e-53</td>
</tr>
<tr class="even">
<td align="center"><strong>income</strong></td>
<td align="center">-3.958e-06</td>
<td align="center">1.147e-05</td>
<td align="center">-0.3452</td>
<td align="center">0.7299</td>
</tr>
<tr class="odd">
<td align="center"><strong>balance</strong></td>
<td align="center">0.0056</td>
<td align="center">0.000321</td>
<td align="center">17.45</td>
<td align="center">3.57e-68</td>
</tr>
<tr class="even">
<td align="center"><strong>studentYes</strong></td>
<td align="center">-0.8668</td>
<td align="center">0.3276</td>
<td align="center">-2.646</td>
<td align="center">0.008155</td>
</tr>
</tbody>
</table>
<p>(Dispersion parameter for binomial family taken to be 1 )</p>
<table style="width:69%;">
<colgroup>
<col width="29%" />
<col width="40%" />
</colgroup>
<tbody>
<tr class="odd">
<td align="center">Null deviance:</td>
<td align="center">1463.7 on 4999 degrees of freedom</td>
</tr>
<tr class="even">
<td align="center">Residual deviance:</td>
<td align="center">810.7 on 4996 degrees of freedom</td>
</tr>
</tbody>
</table>
<blockquote>
<p>The validation set error for this data is 4.83%</p>
</blockquote>
<blockquote>
<p>Adding the <code>student</code> dummy variable to the logistic regression model didn’t change the error by any signifigant amount. The test error rate is within the range of previous test error rates without the <code>student</code> variable</p>
</blockquote>
</div>
